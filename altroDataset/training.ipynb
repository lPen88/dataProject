{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90851488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087e59e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risultati per il cluster Lifestyle:\n",
      "                     Accuracy  Precision    Recall  F1 Score\n",
      "Logistic Regression  0.526805   0.501650  0.571859  0.534459\n",
      "Random Forest        0.583274   0.550842  0.664409  0.602319\n",
      "SVM                  0.500715   0.484038  0.775771  0.596126\n",
      "KNN                  0.561115   0.533870  0.598947  0.564539\n",
      "Gradient Boosting    0.558971   0.528460  0.663657  0.588392\n",
      "\n",
      "Risultati per il cluster Clinical:\n",
      "                     Accuracy  Precision    Recall  F1 Score\n",
      "Logistic Regression  0.495711   0.477146  0.644093  0.548191\n",
      "Random Forest        0.725518   0.695743  0.750188  0.721941\n",
      "SVM                  0.494996   0.478462  0.702032  0.569076\n",
      "KNN                  0.654039   0.601920  0.802107  0.687742\n",
      "Gradient Boosting    0.552538   0.521096  0.715576  0.603044\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Caricamento del dataset\n",
    "df = pd.read_csv(\"Heart_Attack_Prediction.csv\")\n",
    "\n",
    "# Mappatura della colonna 'Gender'\n",
    "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# Encoding di eventuali altre colonne categoriche\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if col != 'Heart_Attack_Risk':\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Definizione dei cluster di feature\n",
    "lifestyle_features = ['Smoking', 'Alcohol_Consumption', 'Physical_Activity', 'Diet_Score', 'Stress_Level']\n",
    "clinical_features = ['Cholesterol_Level', 'LDL_Level', 'HDL_Level', 'Systolic_BP', 'Diastolic_BP']\n",
    "\n",
    "# Funzione per addestrare e valutare i modelli su un sottoinsieme di feature\n",
    "def train_and_evaluate(X, y):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        results[name] = {\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"Precision\": precision_score(y_test, y_pred),\n",
    "            \"Recall\": recall_score(y_test, y_pred),\n",
    "            \"F1 Score\": f1_score(y_test, y_pred)\n",
    "        }\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "# Target\n",
    "y = df['Heart_Attack_Risk']\n",
    "\n",
    "# Addestramento e valutazione per cluster Lifestyle\n",
    "X_lifestyle = df[lifestyle_features]\n",
    "results_lifestyle = train_and_evaluate(X_lifestyle, y)\n",
    "\n",
    "# Addestramento e valutazione per cluster Clinical\n",
    "X_clinical = df[clinical_features]\n",
    "results_clinical = train_and_evaluate(X_clinical, y)\n",
    "\n",
    "# Stampa dei risultati\n",
    "print(\"Risultati per il cluster Lifestyle:\")\n",
    "print(results_lifestyle)\n",
    "\n",
    "print(\"\\nRisultati per il cluster Clinical:\")\n",
    "print(results_clinical)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074c62f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Reports for Lifestyle Cluster:\n",
      "\n",
      "--- Logistic Regression ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.52      1469\n",
      "           1       0.50      0.57      0.53      1329\n",
      "\n",
      "    accuracy                           0.53      2798\n",
      "   macro avg       0.53      0.53      0.53      2798\n",
      "weighted avg       0.53      0.53      0.53      2798\n",
      "\n",
      "--- Random Forest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.56      1469\n",
      "           1       0.55      0.66      0.60      1329\n",
      "\n",
      "    accuracy                           0.58      2798\n",
      "   macro avg       0.59      0.59      0.58      2798\n",
      "weighted avg       0.59      0.58      0.58      2798\n",
      "\n",
      "--- SVM ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.25      0.35      1469\n",
      "           1       0.48      0.78      0.60      1329\n",
      "\n",
      "    accuracy                           0.50      2798\n",
      "   macro avg       0.52      0.51      0.47      2798\n",
      "weighted avg       0.52      0.50      0.46      2798\n",
      "\n",
      "--- KNN ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1469\n",
      "           1       0.53      0.60      0.56      1329\n",
      "\n",
      "    accuracy                           0.56      2798\n",
      "   macro avg       0.56      0.56      0.56      2798\n",
      "weighted avg       0.56      0.56      0.56      2798\n",
      "\n",
      "--- Gradient Boosting ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.46      0.53      1469\n",
      "           1       0.53      0.66      0.59      1329\n",
      "\n",
      "    accuracy                           0.56      2798\n",
      "   macro avg       0.57      0.56      0.56      2798\n",
      "weighted avg       0.57      0.56      0.56      2798\n",
      "\n",
      "\n",
      "Classification Reports for Clinical Cluster:\n",
      "\n",
      "--- Logistic Regression ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.36      0.43      1469\n",
      "           1       0.48      0.64      0.55      1329\n",
      "\n",
      "    accuracy                           0.50      2798\n",
      "   macro avg       0.50      0.50      0.49      2798\n",
      "weighted avg       0.50      0.50      0.49      2798\n",
      "\n",
      "--- Random Forest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71      1469\n",
      "           1       0.67      0.74      0.71      1329\n",
      "\n",
      "    accuracy                           0.71      2798\n",
      "   macro avg       0.71      0.71      0.71      2798\n",
      "weighted avg       0.71      0.71      0.71      2798\n",
      "\n",
      "--- SVM ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.31      0.39      1469\n",
      "           1       0.48      0.70      0.57      1329\n",
      "\n",
      "    accuracy                           0.49      2798\n",
      "   macro avg       0.51      0.50      0.48      2798\n",
      "weighted avg       0.51      0.49      0.48      2798\n",
      "\n",
      "--- KNN ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.52      0.61      1469\n",
      "           1       0.60      0.80      0.69      1329\n",
      "\n",
      "    accuracy                           0.65      2798\n",
      "   macro avg       0.67      0.66      0.65      2798\n",
      "weighted avg       0.68      0.65      0.65      2798\n",
      "\n",
      "--- Gradient Boosting ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.41      0.49      1469\n",
      "           1       0.52      0.72      0.60      1329\n",
      "\n",
      "    accuracy                           0.55      2798\n",
      "   macro avg       0.57      0.56      0.55      2798\n",
      "weighted avg       0.57      0.55      0.54      2798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Caricamento del dataset\n",
    "df = pd.read_csv(\"Heart_Attack_Prediction.csv\")\n",
    "\n",
    "# Mappatura della colonna 'Gender'\n",
    "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# Encoding di eventuali altre colonne categoriche\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if col != 'Heart_Attack_Risk':\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Definizione dei cluster di feature\n",
    "lifestyle_features = ['Smoking', 'Alcohol_Consumption', 'Physical_Activity', 'Diet_Score', 'Stress_Level']\n",
    "clinical_features = ['Cholesterol_Level', 'LDL_Level', 'HDL_Level', 'Systolic_BP', 'Diastolic_BP']\n",
    "\n",
    "best_params = {\n",
    "    'n_estimators': 300,\n",
    "    'max_depth': 25,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Funzione per addestrare e stampare classification_report\n",
    "def train_and_report(X, y, cluster_name):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(**best_params),\n",
    "        \"SVM\": SVC(),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "    }\n",
    "\n",
    "    print(f\"\\nClassification Reports for {cluster_name} Cluster:\\n\")\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"--- {name} ---\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Target\n",
    "y = df['Heart_Attack_Risk']\n",
    "\n",
    "# Addestramento e stampa report per cluster Lifestyle\n",
    "X_lifestyle = df[lifestyle_features]\n",
    "train_and_report(X_lifestyle, y, \"Lifestyle\")\n",
    "\n",
    "# Addestramento e stampa report per cluster Clinical\n",
    "X_clinical = df[clinical_features]\n",
    "train_and_report(X_clinical, y, \"Clinical\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18394a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11202cf8",
   "metadata": {},
   "source": [
    "OTTIMIZZATORE BAYESIANO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d1dfde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found: OrderedDict({'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300})\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71      1469\n",
      "           1       0.67      0.74      0.71      1329\n",
      "\n",
      "    accuracy                           0.71      2798\n",
      "   macro avg       0.71      0.71      0.71      2798\n",
      "weighted avg       0.71      0.71      0.71      2798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Caricamento del dataset\n",
    "df = pd.read_csv(\"Heart_Attack_Prediction.csv\")\n",
    "\n",
    "# Mappatura della colonna 'Gender'\n",
    "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# Encoding di eventuali altre colonne categoriche\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if col != 'Heart_Attack_Risk':\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Selezione delle feature Clinical\n",
    "clinical_features = ['Cholesterol_Level', 'LDL_Level', 'HDL_Level', 'Systolic_BP', 'Diastolic_BP']\n",
    "X = df[clinical_features]\n",
    "y = df['Heart_Attack_Risk']\n",
    "\n",
    "# Bilanciamento con SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Divisione in train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Spazio di ricerca per BayesSearchCV\n",
    "search_space = {\n",
    "    'n_estimators': (50, 300),\n",
    "    'max_depth': (3, 30),\n",
    "    'min_samples_split': (2, 10),\n",
    "    'min_samples_leaf': (1, 10)\n",
    "}\n",
    "\n",
    "# Ottimizzazione bayesiana\n",
    "opt = BayesSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    search_spaces=search_space,\n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Addestramento\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# Valutazione\n",
    "y_pred = opt.predict(X_test)\n",
    "print(\"Best Parameters Found:\", opt.best_params_)\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
