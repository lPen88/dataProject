{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84172f9d",
   "metadata": {},
   "source": [
    "Dopo il bilanciamento del dataset.\n",
    "\n",
    "Prova di modelli, su entrambi i dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2642af6d",
   "metadata": {},
   "source": [
    "SMOTE DATASET (smoteDataset.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62fd81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Logistic Regression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.54      0.55      1244\n",
      "         1.0       0.56      0.57      0.56      1275\n",
      "\n",
      "    accuracy                           0.55      2519\n",
      "   macro avg       0.55      0.55      0.55      2519\n",
      "weighted avg       0.55      0.55      0.55      2519\n",
      "\n",
      "\n",
      "Classification Report for K-Nearest Neighbors:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.47      0.55      1244\n",
      "         1.0       0.59      0.75      0.66      1275\n",
      "\n",
      "    accuracy                           0.62      2519\n",
      "   macro avg       0.62      0.61      0.61      2519\n",
      "weighted avg       0.62      0.62      0.61      2519\n",
      "\n",
      "\n",
      "Classification Report for Decision Tree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.61      0.62      1244\n",
      "         1.0       0.63      0.65      0.64      1275\n",
      "\n",
      "    accuracy                           0.63      2519\n",
      "   macro avg       0.63      0.63      0.63      2519\n",
      "weighted avg       0.63      0.63      0.63      2519\n",
      "\n",
      "\n",
      "Classification Report for Gradient Boosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.88      0.73      1244\n",
      "         1.0       0.81      0.50      0.61      1275\n",
      "\n",
      "    accuracy                           0.68      2519\n",
      "   macro avg       0.72      0.69      0.67      2519\n",
      "weighted avg       0.72      0.68      0.67      2519\n",
      "\n",
      "\n",
      "Classification Report for Naive Bayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.25      0.35      1244\n",
      "         1.0       0.53      0.81      0.64      1275\n",
      "\n",
      "    accuracy                           0.54      2519\n",
      "   macro avg       0.55      0.53      0.50      2519\n",
      "weighted avg       0.55      0.54      0.50      2519\n",
      "\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.81      0.73      1244\n",
      "         1.0       0.77      0.61      0.68      1275\n",
      "\n",
      "    accuracy                           0.71      2519\n",
      "   macro avg       0.72      0.71      0.70      2519\n",
      "weighted avg       0.72      0.71      0.70      2519\n",
      "\n",
      "\n",
      "Classification Report for Support Vector Machine:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.47      0.51      1244\n",
      "         1.0       0.55      0.64      0.59      1275\n",
      "\n",
      "    accuracy                           0.55      2519\n",
      "   macro avg       0.56      0.55      0.55      2519\n",
      "weighted avg       0.56      0.55      0.55      2519\n",
      "\n",
      "\n",
      "Confronto delle performance:\n",
      "\n",
      "                        Accuracy  Precision    Recall  F1 Score\n",
      "Logistic Regression     0.554982   0.554906  0.554982  0.554906\n",
      "K-Nearest Neighbors     0.615324   0.623013  0.615324  0.607552\n",
      "Decision Tree           0.631203   0.631194  0.631203  0.631031\n",
      "Gradient Boosting       0.684002   0.718221  0.684002  0.672416\n",
      "Naive Bayes             0.537515   0.549548  0.537515  0.497653\n",
      "Random Forest           0.707424   0.718086  0.707424  0.704445\n",
      "Support Vector Machine  0.554982   0.555428  0.554982  0.551985\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Carica il dataset\n",
    "df = pd.read_csv('dataset/smoteDataset.csv')\n",
    "\n",
    "# Prepara le feature e il target\n",
    "X = df.drop(\"Heart Attack Risk\", axis=1)\n",
    "y = df[\"Heart Attack Risk\"].astype(\"category\")\n",
    "\n",
    "# Suddivide in training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definisce i modelli\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Support Vector Machine\": SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# Addestra e valuta ciascun modello\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    print(f\"\\nClassification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Mostra i risultati in tabella\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nConfronto delle performance:\\n\")\n",
    "print(results_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e457d7b",
   "metadata": {},
   "source": [
    "UNDERSAMPLED DATASET (undersamplerData.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e1a2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Logistic Regression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.42      0.47       728\n",
      "         1.0       0.49      0.58      0.53       691\n",
      "\n",
      "    accuracy                           0.50      1419\n",
      "   macro avg       0.50      0.50      0.50      1419\n",
      "weighted avg       0.50      0.50      0.50      1419\n",
      "\n",
      "\n",
      "Classification Report for K-Nearest Neighbors:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.51      0.53       728\n",
      "         1.0       0.51      0.54      0.52       691\n",
      "\n",
      "    accuracy                           0.52      1419\n",
      "   macro avg       0.52      0.52      0.52      1419\n",
      "weighted avg       0.52      0.52      0.52      1419\n",
      "\n",
      "\n",
      "Classification Report for Decision Tree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.51      0.53       728\n",
      "         1.0       0.52      0.56      0.54       691\n",
      "\n",
      "    accuracy                           0.53      1419\n",
      "   macro avg       0.53      0.53      0.53      1419\n",
      "weighted avg       0.54      0.53      0.53      1419\n",
      "\n",
      "\n",
      "Classification Report for Gradient Boosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.41      0.46       728\n",
      "         1.0       0.49      0.60      0.54       691\n",
      "\n",
      "    accuracy                           0.50      1419\n",
      "   macro avg       0.50      0.50      0.50      1419\n",
      "weighted avg       0.50      0.50      0.50      1419\n",
      "\n",
      "\n",
      "Classification Report for Naive Bayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.36      0.42       728\n",
      "         1.0       0.49      0.65      0.56       691\n",
      "\n",
      "    accuracy                           0.50      1419\n",
      "   macro avg       0.50      0.50      0.49      1419\n",
      "weighted avg       0.50      0.50      0.49      1419\n",
      "\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.53      0.54       728\n",
      "         1.0       0.52      0.53      0.52       691\n",
      "\n",
      "    accuracy                           0.53      1419\n",
      "   macro avg       0.53      0.53      0.53      1419\n",
      "weighted avg       0.53      0.53      0.53      1419\n",
      "\n",
      "\n",
      "Classification Report for Support Vector Machine:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.37      0.44       728\n",
      "         1.0       0.50      0.66      0.57       691\n",
      "\n",
      "    accuracy                           0.51      1419\n",
      "   macro avg       0.52      0.51      0.50      1419\n",
      "weighted avg       0.52      0.51      0.50      1419\n",
      "\n",
      "\n",
      "Confronto delle performance:\n",
      "\n",
      "                        Accuracy  Precision    Recall  F1 Score\n",
      "Logistic Regression     0.501057   0.503579  0.501057  0.497936\n",
      "K-Nearest Neighbors     0.524313   0.524943  0.524313  0.524344\n",
      "Decision Tree           0.534179   0.535231  0.534179  0.534014\n",
      "Gradient Boosting       0.501762   0.504840  0.501762  0.497066\n",
      "Naive Bayes             0.500352   0.504856  0.500352  0.489880\n",
      "Random Forest           0.531360   0.531595  0.531360  0.531433\n",
      "Support Vector Machine  0.510218   0.515629  0.510218  0.500158\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Carica il dataset\n",
    "df = pd.read_csv('dataset/undersamplerDataset.csv')\n",
    "\n",
    "# Prepara le feature e il target\n",
    "X = df.drop(\"Heart Attack Risk\", axis=1)\n",
    "y = df[\"Heart Attack Risk\"].astype(\"category\")\n",
    "\n",
    "# Suddivide in training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definisce i modelli\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Support Vector Machine\": SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# Addestra e valuta ciascun modello\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    print(f\"\\nClassification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Mostra i risultati in tabella\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nConfronto delle performance:\\n\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
